const { createToken, Lexer } = require("chevrotain");

// Definición de tokens utilizando Chevrotain
const WhiteSpace = createToken({ name: "WhiteSpace", pattern: /\s+/, group:
Lexer.SKIPPED });
const Comment = createToken({ name: "Comment", pattern: /\/\/.*/ });
const NumberLiteral = createToken({ name: "NumberLiteral", pattern: /\d+/ });
const StringLiteral = createToken({ name: "StringLiteral", pattern:
/"(?:[^\\"]|\\.)*"/ });
const Keyword = createToken({ name: "Keyword", pattern: Lexer.NA });
const True = createToken({ name: "True", pattern: /true\b/ });
const False = createToken({ name: "False", pattern: /false\b/ });
const Null = createToken({ name: "Null", pattern: /null\b/ });
const Identifier = createToken({ name: "Identifier", pattern: /[a-zA-Z]\w*/ });
const LParen = createToken({ name: "LParen", pattern: /\(/ });
const RParen = createToken({ name: "RParen", pattern: /\)/ });
const LBrace = createToken({ name: "LBrace", pattern: /{/ });
const RBrace = createToken({ name: "RBrace", pattern: /}/ });
const SemiColon = createToken({ name: "SemiColon", pattern: /;/ });
const Assign = createToken({ name: "Assign", pattern: /=/ });
const Dot = createToken({ name: "Dot", pattern: /\./ });

// Define las palabras clave
const keywords = {
"if": Keyword,
"else": Keyword,
"while": Keyword,
"for": Keyword,
"int": Keyword,
"double": Keyword,
"boolean": Keyword,
"true": True,
"false": False,
"null": Null
};

// Agrega las palabras clave al léxico
Object.keys(keywords).forEach(keyword => {
keywords[keyword].LONGER_ALT("Identifier");
});

// Agrupa todos los tokens en un array
const allTokens = [
WhiteSpace,
Comment,
NumberLiteral,
StringLiteral,
True,
False,
Null,
Identifier,
LParen,
RParen,
LBrace,
RBrace,
SemiColon,
Assign,
Dot
];

// Crea el lexer
const JavaLexer = new Lexer(allTokens);

// Función para analizar la entrada
function tokenize(inputText) {
const lexResult = JavaLexer.tokenize(inputText);

if (lexResult.errors.length > 0) {
throw new Error("Error de análisis léxico: " + lexResult.errors[0].message);
}

return lexResult.tokens;
}

// Ejemplo de uso
const inputText = `int x = 42;
String message = "Hello, world!";
System.out.println(message);`;

const tokens = tokenize(inputText);
tokens.forEach(token => {
console.log(`Token ${token.tokenType.name}: ${token.image}`);
});
